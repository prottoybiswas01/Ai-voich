<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Assistant</title>
    <!-- Tailwind CSS CDN for easy styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body {
            font-family: "Inter", sans-serif;
            margin: 0;
            padding: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #fff;
            overflow: hidden; /* Prevent scrollbars */
        }
        .container {
            background-color: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.2);
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
            border-radius: 20px;
            padding: 2.5rem;
            width: 90%;
            max-width: 500px;
            text-align: center;
            animation: fadeIn 1s ease-out;
            display: flex;
            flex-direction: column;
            gap: 1.5rem;
        }
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-20px); }
            to { opacity: 1; transform: translateY(0); }
        }
        .microphone-button {
            background: linear-gradient(45deg, #10b981 0%, #059669 100%);
            border: none;
            color: white;
            padding: 1.25rem;
            border-radius: 9999px; /* Fully rounded */
            cursor: pointer;
            font-size: 2.5rem;
            display: inline-flex;
            justify-content: center;
            align-items: center;
            box-shadow: 0 4px 15px rgba(16, 185, 129, 0.4);
            transition: all 0.3s ease;
            position: relative;
            margin: 0 auto; /* Center the button */
        }
        .microphone-button:hover {
            transform: scale(1.05) translateY(-2px);
            box-shadow: 0 6px 20px rgba(16, 185, 129, 0.6);
        }
        .microphone-button:active {
            transform: scale(0.98);
        }
        .microphone-button.listening {
            animation: pulse 1.5s infinite;
            background: linear-gradient(45deg, #ef4444 0%, #dc2626 100%); /* Red when listening */
            box-shadow: 0 4px 15px rgba(239, 68, 68, 0.5);
        }
        @keyframes pulse {
            0% { transform: scale(1); opacity: 1; }
            50% { transform: scale(1.1); opacity: 0.8; }
            100% { transform: scale(1); opacity: 1; }
        }
        .message-box {
            background-color: rgba(255, 255, 255, 0.15);
            border-radius: 15px;
            padding: 1rem 1.5rem;
            min-height: 80px;
            display: flex;
            align-items: center;
            justify-content: center;
            text-align: left;
            word-wrap: break-word;
            line-height: 1.6;
            font-size: 1.1rem;
        }
        .user-message {
            background-color: rgba(147, 197, 253, 0.2);
            color: #e0f2fe;
        }
        .ai-message {
            background-color: rgba(253, 230, 138, 0.2);
            color: #fffbeb;
        }
        .loading-indicator {
            display: none;
            margin-top: 1rem;
            font-size: 1.2rem;
            color: #d1d5db;
        }
        .loading-indicator.active {
            display: block;
        }

        /* Responsive adjustments */
        @media (max-width: 600px) {
            .container {
                padding: 1.5rem;
            }
            .microphone-button {
                font-size: 2rem;
                padding: 1rem;
            }
            .message-box {
                font-size: 1rem;
                min-height: 60px;
            }
            h1 {
                font-size: 1.8rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1 class="text-3xl font-extrabold mb-4">Voice Assistant</h1>
        <p class="text-md text-gray-200 mb-6">Press the microphone to start speaking.</p>

        <button id="microphoneBtn" class="microphone-button">
            <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" class="w-10 h-10">
                <path stroke-linecap="round" stroke-linejoin="round" d="M12 18.75a6 6 0 0 0 6-6v-1.5m-6 7.5a6 6 0 0 1-6-6v-1.5m6 7.5v3.75m-3.75 0h7.5M12 10.5v3.75m0-7.5V1.5m7.5 7.5h-1.5m-6 0h-3M12 22.5c2.25 0 4.5-.75 4.5-2.25V18a4.5 4.5 0 0 0-4.5-4.5h-1.5a4.5 4.5 0 0 0-4.5 4.5v2.25c0 1.5 2.25 2.25 4.5 2.25z" />
            </svg>
        </button>

        <div id="userOutput" class="message-box user-message hidden"></div>
        <div id="aiOutput" class="message-box ai-message hidden"></div>
        <div id="loadingIndicator" class="loading-indicator">Thinking...</div>
    </div>

    <script>
        // Ensure the DOM is fully loaded before running script
        window.onload = function() {
            const microphoneBtn = document.getElementById('microphoneBtn');
            const userOutput = document.getElementById('userOutput');
            const aiOutput = document.getElementById('aiOutput');
            const loadingIndicator = document.getElementById('loadingIndicator');

            // Check for Web Speech API compatibility
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            const SpeechSynthesis = window.speechSynthesis;

            if (!SpeechRecognition) {
                userOutput.textContent = "Speech Recognition not supported in this browser. Please use Chrome or Edge.";
                userOutput.classList.remove('hidden');
                microphoneBtn.disabled = true;
                microphoneBtn.style.cursor = 'not-allowed';
                return;
            }

            const recognition = new SpeechRecognition();
            recognition.continuous = false; // Stop after first utterance
            recognition.lang = 'en-US';
            recognition.interimResults = false; // Only final results
            recognition.maxAlternatives = 1; // Only get the most probable result

            let isListening = false; // Track listening state

            // Function to speak text
            function speak(text) {
                if (SpeechSynthesis) {
                    const utterance = new SpeechSynthesisUtterance(text);
                    utterance.lang = 'en-US';
                    utterance.pitch = 1;
                    utterance.rate = 1; // Normal speed
                    utterance.volume = 1; // Max volume

                    // Set a friendly voice if available
                    utterance.onvoiceschanged = () => {
                        const voices = SpeechSynthesis.getVoices();
                        const preferredVoice = voices.find(voice => voice.name === 'Google US English' || voice.name.includes('Samantha') || voice.name.includes('Alex'));
                        if (preferredVoice) {
                            utterance.voice = preferredVoice;
                        }
                    };
                    SpeechSynthesis.speak(utterance);
                    return new Promise(resolve => {
                        utterance.onend = resolve;
                    });
                } else {
                    console.warn("Speech Synthesis not supported.");
                    return Promise.resolve();
                }
            }

            // Simple AI response logic
            async function getAIResponse(message) {
                loadingIndicator.classList.add('active');
                await new Promise(resolve => setTimeout(resolve, 1000)); // Simulate thinking time

                let response = "I'm sorry, I don't have an answer for that right now. Could you ask me something else?";

                if (message.toLowerCase().includes("hello") || message.toLowerCase().includes("hi")) {
                    response = "Hello there! How can I help you today?";
                } else if (message.toLowerCase().includes("how are you")) {
                    response = "I'm just a computer program, so I don't have feelings, but I'm ready to assist you!";
                } else if (message.toLowerCase().includes("your name")) {
                    response = "I am a simple voice assistant created by an LLM.";
                } else if (message.toLowerCase().includes("time")) {
                    const now = new Date();
                    response = `The current time is ${now.toLocaleTimeString()}.`;
                } else if (message.toLowerCase().includes("date")) {
                    const now = new Date();
                    response = `Today's date is ${now.toLocaleDateString()}.`;
                } else if (message.toLowerCase().includes("weather")) {
                    response = "I cannot access real-time weather information at the moment.";
                } else if (message.toLowerCase().includes("goodbye") || message.toLowerCase().includes("bye")) {
                    response = "Goodbye! Have a great day!";
                }
                loadingIndicator.classList.remove('active');
                return response;
            }

            // Event handler for when recognition starts
            recognition.onstart = function() {
                isListening = true;
                microphoneBtn.classList.add('listening');
                userOutput.classList.add('hidden');
                aiOutput.classList.add('hidden');
                loadingIndicator.classList.remove('active');
                userOutput.textContent = "Listening...";
                userOutput.classList.remove('hidden');
                console.log('Voice recognition started.');
            };

            // Event handler for when a result is received
            recognition.onresult = async function(event) {
                const transcript = event.results[0][0].transcript;
                userOutput.textContent = `You said: "${transcript}"`;
                userOutput.classList.remove('hidden');
                console.log('User said:', transcript);

                // Get AI response and speak it
                const aiResponse = await getAIResponse(transcript);
                aiOutput.textContent = `AI: "${aiResponse}"`;
                aiOutput.classList.remove('hidden');
                await speak(aiResponse);
                console.log('AI responded:', aiResponse);
            };

            // Event handler for errors
            recognition.onerror = function(event) {
                console.error('Speech recognition error:', event.error);
                userOutput.textContent = `Error: ${event.error}. Please try again.`;
                userOutput.classList.remove('hidden');
                microphoneBtn.classList.remove('listening');
                isListening = false;
                loadingIndicator.classList.remove('active');
            };

            // Event handler for when recognition ends
            recognition.onend = function() {
                isListening = false;
                microphoneBtn.classList.remove('listening');
                console.log('Voice recognition ended.');
            };

            // Click listener for the microphone button
            microphoneBtn.addEventListener('click', () => {
                if (isListening) {
                    recognition.stop();
                } else {
                    try {
                        recognition.start();
                    } catch (e) {
                        console.error("Recognition already started or an error occurred:", e);
                        userOutput.textContent = "Oops! Something went wrong. Please wait a moment and try again.";
                        userOutput.classList.remove('hidden');
                        microphoneBtn.classList.remove('listening');
                        isListening = false;
                    }
                }
            });
        };
    </script>
</body>
</html>
